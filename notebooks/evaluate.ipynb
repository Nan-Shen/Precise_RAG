{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bf8f47-cd2b-4cbc-a812-484b785159d9",
   "metadata": {},
   "source": [
    "# Aim:\n",
    "Assess the performance of different RAG methods in financial documents analysis (primary background investigation for consulting, stock purchase) \n",
    "\n",
    "# Assessment criteria:\n",
    "1. relevance\n",
    "2. length of retrieved context\n",
    "3. <s>speed\n",
    "4. <s>cost\n",
    "\n",
    "# Methods to test:\n",
    "1. Dense Embeddings\n",
    "   1.1 parameters\n",
    "   1.2 <s>finetune embedding model (need GPU machine, too expensive for now)\n",
    "2. ColBERT\n",
    "4. Hybrid retriever and rerank\n",
    "5. <s>Knowledge Augmented Generation (KAG, need to build a domain-specific architecture from sratch)\n",
    "6. <s>Contextual retrieval preprocessing (use llm to search through all chunks, too expensive)\n",
    "\n",
    "# Test questions:\n",
    "\n",
    "Test questions were designed to assess retrieval methods' performance under different senario. The first four questions require coarse search and return text content. Q3 and Q4 require large pieces of context. The last seven questions need precise search to return one specific number and some of them are from tables. Q5 and Q6 have similar keyword but difference in numeric description(2025 revenue of NVDIA and 2024 revenue of NVDIA). Q7 vs Q10 (total liabilities vs total current liabilities), Q9 and Q10 (total current assets vs total current liabilities) were designed in similar way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c236f704-baab-4b43-8cc3-806d66766f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39ebce19-7799-4f1c-963b-a5509848ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_strreplace(string, replace_dic):\n",
    "    for k,v in replace_dic.items():\n",
    "        string = string.replace(k,v)\n",
    "    return string\n",
    "\n",
    "def parse_queries(qa_fp, replace_dic):\n",
    "    qa = pd.read_csv(qa_fp)\n",
    "    queries = list(map(lambda query: multiple_strreplace(query, replace_dic), qa['question'].values))\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a601ad0a-1839-404b-9d7a-99269ac42e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = 'NVDIA'\n",
    "year1, year2 = 2025, 2024\n",
    "qa_fp = '../inputs/Q-A.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "919e6b8d-eed0-4093-9176-c79ca6874599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What kind of products or services is NVDIA providing?',\n",
       " 'Who are the customers of NVDIA or what types of markets are NVDIA operating in?',\n",
       " 'Who are the competitors of NVDIA?',\n",
       " \"What are the risk factors and uncertainties that could affect the NVDIA's future performance?\",\n",
       " 'What is the 2025 revenue of NVDIA?',\n",
       " 'What is the 2024 revenue of NVDIA?',\n",
       " 'What is the 2025 total liabilities?',\n",
       " \"What is the 2025 total shareholders' equity?\",\n",
       " 'What is the 2025 total current assets?',\n",
       " 'What is the 2025 total current liabilities?',\n",
       " 'What is the 2025 gross margin?']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_dic = {'{company_name}':'NVDIA',\n",
    "              '{year1}':str(year1),\n",
    "               '{year2}':str(year2)}\n",
    "parse_queries(qa_fp, replace_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1949908-e1e3-4ee9-8a76-2a77dd6f6c7c",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The eleven questions listed above were used as test instructions for different retrieval methods. Each method will return 5 pieces of documents. Columns 'Q1' to 'Q11' bellow were number of retrived documents relevent to the corresponding instruction and containing information to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbce50e0-dfac-4a79-ab8a-d6fa7c93c72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dense embed</td>\n",
       "      <td>minishlab/potion-base-8M</td>\n",
       "      <td>500/100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dense embed</td>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>500/100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method                     model parameters  Q1  Q2  Q3  Q4  Q5  Q6  \\\n",
       "0  dense embed  minishlab/potion-base-8M    500/100   1   0   0   3   1   0   \n",
       "1  dense embed     BAAI/bge-base-en-v1.5    500/100   0   0   1   3   1   0   \n",
       "\n",
       "   Q7  Q8  Q9  Q10  Q11       ave  \n",
       "0   0   1   0    0    0  0.545455  \n",
       "1   0   0   2    1    0  0.727273  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.read_csv('../outputs/retriever_score.csv')\n",
    "scores.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9183a-4027-4c61-b127-a26cee973818",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cols = list(filter(lambda x: x[0] == 'Q', scores.columns.tolist()))\n",
    "scores['ave'] = scores[s_cols].mean(axis=1)\n",
    "scores['answered'] = (scores[s_cols]>0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09e6e471-f18b-487d-8849-baf87a6beddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>ave</th>\n",
       "      <th>answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dense embed</td>\n",
       "      <td>minishlab/potion-base-8M</td>\n",
       "      <td>500/100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dense embed</td>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>500/100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dense embed</td>\n",
       "      <td>minishlab/potion-base-8M</td>\n",
       "      <td>800/100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dense embed</td>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>800/100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colbert</td>\n",
       "      <td>colbertv2.0</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>colbertv2.0+BM25+BAAI/bge-reranker-base</td>\n",
       "      <td>0.7/0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method                                    model parameters  Q1  Q2  \\\n",
       "0  dense embed                 minishlab/potion-base-8M    500/100   1   0   \n",
       "1  dense embed                    BAAI/bge-base-en-v1.5    500/100   0   0   \n",
       "2  dense embed                 minishlab/potion-base-8M    800/100   1   0   \n",
       "3  dense embed                    BAAI/bge-base-en-v1.5    800/100   0   1   \n",
       "4      colbert                              colbertv2.0        512   2   4   \n",
       "5       hybrid  colbertv2.0+BM25+BAAI/bge-reranker-base    0.7/0.3   3   1   \n",
       "\n",
       "   Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Q11       ave  answered  \n",
       "0   0   3   1   0   0   1   0    0    0  0.545455         4  \n",
       "1   1   3   1   0   0   0   2    1    0  0.727273         5  \n",
       "2   1   1   1   1   1   1   0    0    0  0.636364         7  \n",
       "3   1   3   1   1   0   1   1    1    0  0.909091         8  \n",
       "4   0   5   3   3   3   1   1    1    2  2.272727        10  \n",
       "5   2   5   3   3   1   1   1    1    4  2.272727        11  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1839046-abc6-48c8-b274-167260997a20",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "Hybrid search combined ColBert, BM25 and reranker had the best performance. ColBert had significantly better performance than dense embeddings. Keyword search did not contribute too much in hybrid search. But rerank put the most relevent content on top, especially in precise searched. Between two dense embedding models, the one with more parameters worked better and also large context will improve the performance. Due to the limitation of fund and time, I did not explore larger or fine tuned embedding models and those may outperform all the methods included in this study."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
